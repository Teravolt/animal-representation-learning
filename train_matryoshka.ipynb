{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using Google Collab, you can import the following:\n",
    "# %pip install -U datasets transformers accelerate ftfy pyarrow wandb pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "import torch\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "from torchvision import transforms\n",
    "import wandb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from accelerate.utils import write_basic_config\n",
    "\n",
    "# write_basic_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() \\\n",
    "        else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "# DEVICE = 'cpu'\n",
    "\n",
    "CONFIG = Namespace(\n",
    "    run_name='animal-classifier',\n",
    "    model_name='animal-classifier-model-v1',\n",
    "    image_size=128,\n",
    "    hidden_dims=256,\n",
    "    horizontal_flip_prob=0.5,\n",
    "    gaussian_blur_kernel_size=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=4e-4,\n",
    "    seed=1,\n",
    "    beta_schedule='squaredcos_cap_v2',\n",
    "    lr_exp_schedule_gamma=0.85,\n",
    "    lr_warmup_steps=500,\n",
    "    train_limit=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset\n",
    "\n",
    "For now, I am using the following data augmentations:\n",
    "- RandomHorizontalFlip - Randomly flips the image horizontally\n",
    "- GaussianBlur - Smooth/blur image using a Gaussian filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(config: Namespace):\n",
    "    \"\"\"\n",
    "    Prepare dataloader\n",
    "    \"\"\"\n",
    "\n",
    "    preprocess = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((config.image_size, config.image_size)),  # Resize\n",
    "            transforms.RandomHorizontalFlip(p=config.horizontal_flip_prob),\n",
    "            transforms.GaussianBlur(kernel_size=config.gaussian_blur_kernel_size),\n",
    "            transforms.ToTensor(),  # Convert to tensor (0, 1)\n",
    "            transforms.Normalize([0.5], [0.5]),  # Map to (-1, 1)\n",
    "        ])\n",
    "    \n",
    "    original_img_preprocess = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((512, 512)),  # Resize\n",
    "            transforms.ToTensor(),  # Convert to tensor (0, 1)\n",
    "        ])\n",
    "\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = load_dataset('cats_vs_dogs')\n",
    "\n",
    "    # Remove images that are 100x100 or below.\n",
    "    dataset = \\\n",
    "        dataset.filter(\n",
    "            lambda example: example['image'].size[0] > 100 and example['image'].size[1] > 100)\n",
    "\n",
    "    def transform(examples):\n",
    "        images = [preprocess(image.convert('RGB')) for image in examples['image']]\n",
    "        original_images = [\n",
    "            original_img_preprocess(image.convert('RGB')) \\\n",
    "                for image in examples['image']]\n",
    "        return {'image': images,\n",
    "                'label': examples['labels'],\n",
    "                'original-image': original_images\n",
    "                }\n",
    "\n",
    "    num_points = len(dataset['train'])\n",
    "    labels = dataset['train']['labels']\n",
    "\n",
    "    split_df = pd.DataFrame()\n",
    "    split_df['labels'] = labels\n",
    "    split_df['id'] = list(range(num_points))\n",
    "    split_df['fold'] = -1\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=config.seed)\n",
    "    for i, (_, test_ids) in enumerate(cv.split(np.zeros(num_points), labels)):\n",
    "        split_df.loc[test_ids, ['fold']] = i\n",
    "\n",
    "    split_df['split'] = 'train'\n",
    "    split_df.loc[split_df.fold == 0, ['split']] = 'val'\n",
    "\n",
    "    # print(split_df[split_df['split'].str.fullmatch('train')].labels.value_counts())\n",
    "    # print(split_df[split_df['split'].str.fullmatch('val')].labels.value_counts())\n",
    "\n",
    "    train_indices = split_df[split_df['split'].str.fullmatch('train')]['id']\n",
    "    val_indices = split_df[split_df['split'].str.fullmatch('val')]['id']\n",
    "\n",
    "    def train_generator():\n",
    "        for idx in train_indices:\n",
    "            yield dataset['train'][idx]\n",
    "\n",
    "    def val_generator():\n",
    "        for idx in val_indices:\n",
    "            yield dataset['train'][idx]\n",
    "\n",
    "    train_dataset = Dataset.from_generator(train_generator)\n",
    "    val_dataset = Dataset.from_generator(val_generator)\n",
    "\n",
    "    train_dataset.set_transform(transform)\n",
    "    val_dataset.set_transform(transform)\n",
    "\n",
    "    train_gen = torch.Generator().manual_seed(config.seed)\n",
    "    val_gen = torch.Generator().manual_seed(config.seed)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=config.per_device_train_batch_size,\n",
    "        shuffle=True, generator=train_gen)\n",
    "    \n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=config.per_device_eval_batch_size,\n",
    "        shuffle=True, generator=val_gen)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_linear_input_dims():\n",
    "#     \"\"\"\n",
    "#     Compute linear input dimensions\n",
    "#     \"\"\"\n",
    "\n",
    "def compute_loss(pred: torch.Tensor, gt: torch.Tensor,\n",
    "                 weights: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Compute loss\n",
    "    \"\"\"\n",
    "\n",
    "    # Sum over each subset & average over each batch\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    \n",
    "    # Cross entropy loss require (batch_size, num_classes, ...)\n",
    "    pred_ = torch.transpose(pred, 1, 2)\n",
    "    # print(f\"Transposed predictions: {pred_.shape}\")\n",
    "\n",
    "    output = loss_fn(pred_, gt)\n",
    "    # print(f\"Output: {output.shape}\")\n",
    "\n",
    "    loss = output.sum(dim=1).mean()\n",
    "    return loss\n",
    "\n",
    "class AnimalClassifierMatryoshka(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels: int, dims: int,\n",
    "                 num_labels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_1 = torch.nn.Conv2d(\n",
    "            in_channels, dims, kernel_size=5)\n",
    "        self.max_pool_1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv_2 = torch.nn.Conv2d(\n",
    "            dims, 2*dims, kernel_size=5)\n",
    "        self.max_pool_2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv_3 = torch.nn.Conv2d(\n",
    "            2*dims, 4*dims, kernel_size=3)\n",
    "        self.max_pool_3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.projection = torch.nn.LazyLinear(4*dims)\n",
    "\n",
    "        num_subsets = int(np.log2(dims)) + 2\n",
    "        # print(f\"Number of subsets: {num_subsets} - Dimensions: {4*dims}\")\n",
    "\n",
    "        self.linear_layers = torch.nn.ModuleList()\n",
    "        for i in range(3, num_subsets+1):\n",
    "            # print(f\"Number of dimensions: {2**i}\")\n",
    "            self.linear_layers.append(\n",
    "                torch.nn.Linear(2**i, num_labels))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \"\"\"\n",
    "        x_ = self.conv_1(x)\n",
    "        x_ = self.max_pool_1(x_)\n",
    "\n",
    "        # print(f\"Output of conv & max pool 1: {x_.shape}\")\n",
    "\n",
    "        x_ = self.conv_2(x_)\n",
    "        x_ = self.max_pool_2(x_)\n",
    "\n",
    "        # print(f\"Output of conv & max pool 2: {x_.shape}\")\n",
    "\n",
    "        x_ = self.conv_3(x_)\n",
    "        x_ = self.max_pool_3(x_)\n",
    "\n",
    "        # print(f\"Output of conv & max pool 3: {x_.shape}\")\n",
    "\n",
    "        x_ = self.flatten(x_)\n",
    "        # print(f\"Output of flatten: {x_.shape}\")\n",
    "\n",
    "        x_ = self.projection(x_)\n",
    "        # print(f\"Output of projection: {x_.shape}\")\n",
    "\n",
    "        output = []\n",
    "        for i, layer in enumerate(self.linear_layers):\n",
    "            # print(f\"Getting slice: {2**(3+i)}\")\n",
    "            x__ = layer(x_[:, 0:2**(3+i)])\n",
    "            # print(f\"Output: {x__.shape}\")\n",
    "            output.append(x__)\n",
    "\n",
    "        output = torch.stack(output, dim=1)\n",
    "        # print(f\"Final output: {output.shape}\")\n",
    "        return output\n",
    "\n",
    "def create_model(in_dimensions: int, dims: int, num_labels: int):\n",
    "    \"\"\"\n",
    "    Create model\n",
    "    \"\"\"\n",
    "\n",
    "    model = AnimalClassifierMatryoshka(in_dimensions, dims, num_labels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_loop(epoch: int, model, dataloader,\n",
    "              num_subsets: int, wandb_run):\n",
    "    \"\"\"\n",
    "    Evaluation loop\n",
    "    \"\"\"\n",
    "\n",
    "    tensor_to_pil = transforms.ToPILImage()\n",
    "    columns = [f'pred-{i}' for i in range(num_subsets)]\n",
    "\n",
    "    dataframe = []\n",
    "    original_images = []\n",
    "    images = []\n",
    "    gt = []\n",
    "    \n",
    "    for i, batch in enumerate(dataloader):\n",
    "\n",
    "        logits = model(batch['image'])\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        labels = torch.stack(\n",
    "            [batch['label'] for _ in range(logits.shape[1])])\n",
    "        labels = torch.transpose(labels, 1, 0)\n",
    "\n",
    "        loss = compute_loss(logits, labels, None)            \n",
    "\n",
    "        acc = (preds == labels).double()\n",
    "        wandb_run.log({'accuracy': acc.mean()}, commit=False)\n",
    "        wandb_run.log({'val-loss': loss.item()}, commit=False)\n",
    "        \n",
    "        _images = []\n",
    "        _original_images = []\n",
    "        for j in range(batch['image'].shape[0]):\n",
    "            _images.append(tensor_to_pil(batch['image'][j,:]))\n",
    "            _original_images.append(tensor_to_pil(batch['original-image'][j,:]))\n",
    "\n",
    "        images += _images\n",
    "        original_images += _original_images\n",
    "\n",
    "        dataframe += preds.tolist()\n",
    "        gt += batch['label'].tolist()\n",
    "\n",
    "    dataframe = pd.DataFrame(dataframe,\n",
    "                             columns=columns)\n",
    "    dataframe['epoch'] = epoch\n",
    "    dataframe['image'] = \\\n",
    "        [wandb.Image(image) for image in images]\n",
    "    dataframe['original_images'] = \\\n",
    "        [wandb.Image(image) for image in original_images]\n",
    "    dataframe['gt'] = gt\n",
    "\n",
    "    table = wandb.Table(data=dataframe)\n",
    "    wandb_run.log({'eval-table': table})\n",
    "\n",
    "def training_loop(config: Namespace):\n",
    "    \"\"\"\n",
    "    Training loop\n",
    "    \"\"\"\n",
    "\n",
    "    wandb_run = wandb.init(project='Animal-Classifier', entity=None,\n",
    "                           job_type='training',\n",
    "                           name=config.run_name,\n",
    "                           config=config)\n",
    "\n",
    "    set_seed(config.seed)\n",
    "    accelerator = Accelerator(\n",
    "        mixed_precision=config.mixed_precision, cpu=(config.device == 'cpu'))\n",
    "\n",
    "    train_dataloader, val_dataloader = prepare_dataloader(config)    \n",
    "    model = create_model(3, config.hidden_dims, 2)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    scheduler = CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=config.lr_warmup_steps,\n",
    "        last_epoch=config.num_train_epochs*len(train_dataloader))\n",
    "\n",
    "    model, optimizer, train_dataloader, val_dataloader, scheduler = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, val_dataloader, scheduler)\n",
    "\n",
    "    num_steps = 0\n",
    "    for epoch in range(config.num_train_epochs):\n",
    "        model.train()\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch}\")\n",
    "\n",
    "        epoch_loss = 0\n",
    "        num_iters = 0\n",
    "        for _, batch in enumerate(train_dataloader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model(batch['image'])\n",
    "            labels = torch.stack(\n",
    "                [batch['label'] for _ in range(logits.shape[1])])\n",
    "            labels = torch.transpose(labels, 1, 0)\n",
    "\n",
    "            loss = compute_loss(logits, labels, None)            \n",
    "            accelerator.backward(loss)\n",
    "            accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            wandb_run.log({'loss': loss.item()}, commit=False, step=num_steps)\n",
    "            wandb_run.log({'lr': scheduler.get_lr()[0]}, commit=False, step=num_steps)\n",
    "\n",
    "            num_steps += 1\n",
    "            num_iters += 1\n",
    "\n",
    "            # Update the model parameters with the optimizer\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        # Validate model\n",
    "        eval_loop(epoch, model, val_dataloader, 8, wandb_run)\n",
    "\n",
    "        wandb_run.log({'epoch-loss': epoch_loss/num_iters})\n",
    "\n",
    "    # Save model to W&Bs\n",
    "    model_art = wandb.Artifact(CONFIG.model_name, type='model')\n",
    "    torch.save(model.state_dict(), 'model.pt')\n",
    "\n",
    "    model_art.add_file('model.pt')\n",
    "    wandb_run.log_artifact(model_art)\n",
    "    wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from accelerate import notebook_launcher\n",
    "\n",
    "# notebook_launcher(training_loop, (CONFIG, ), num_processes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "animal-representation-learning-yALp4Exd-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
