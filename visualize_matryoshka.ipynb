{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Representations Learned by Matryoshka Representation Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "import wandb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnimalClassifierMatryoshka(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels: int, dims: int,\n",
    "                 num_labels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_1 = torch.nn.Conv2d(\n",
    "            in_channels, dims, kernel_size=12)\n",
    "        self.max_pool_1 = torch.nn.MaxPool2d(kernel_size=3)\n",
    "\n",
    "        self.conv_2 = torch.nn.Conv2d(\n",
    "            dims, 2*dims, kernel_size=5)\n",
    "        self.max_pool_2 = torch.nn.MaxPool2d(kernel_size=3)\n",
    "\n",
    "        self.conv_3 = torch.nn.Conv2d(\n",
    "            2*dims, 2*dims, kernel_size=3)\n",
    "        self.max_pool_3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv_4 = torch.nn.Conv2d(\n",
    "            2*dims, 2*dims, kernel_size=3)\n",
    "        self.max_pool_4 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.projection = torch.nn.LazyLinear(4*dims)\n",
    "\n",
    "        num_subsets = int(np.log2(dims)) + 2\n",
    "        # print(f\"Number of subsets: {num_subsets} - Dimensions: {4*dims}\")\n",
    "\n",
    "        self.linear_layers = torch.nn.ModuleList()\n",
    "        for i in range(3, num_subsets+1):\n",
    "            # print(f\"Number of dimensions: {2**i}\")\n",
    "            self.linear_layers.append(\n",
    "                torch.nn.Linear(2**i, num_labels))\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \"\"\"\n",
    "\n",
    "        x_ = self.conv_1(x)\n",
    "        x_ = self.max_pool_1(x_)\n",
    "        # print(f\"Output of conv & max pool 1: {x_.shape}\")\n",
    "\n",
    "        x_ = self.conv_2(x_)\n",
    "        x_ = self.max_pool_2(x_)\n",
    "        # print(f\"Output of conv & max pool 2: {x_.shape}\")\n",
    "\n",
    "        x_ = self.conv_3(x_)\n",
    "        x_ = self.max_pool_3(x_)\n",
    "        # print(f\"Output of conv & max pool 3: {x_.shape}\")\n",
    "\n",
    "        x_ = self.conv_4(x_)\n",
    "        x_ = self.max_pool_4(x_)\n",
    "        # print(f\"Output of conv & max pool 4: {x_.shape}\")\n",
    "\n",
    "        x_ = self.flatten(x_)\n",
    "        # print(f\"Output of flatten: {x_.shape}\")\n",
    "\n",
    "        x_ = self.projection(x_)\n",
    "        # print(f\"Output of projection: {x_.shape}\")\n",
    "\n",
    "        output = []\n",
    "        for i, layer in enumerate(self.linear_layers):\n",
    "            # print(f\"Getting slice: {2**(3+i)} - {x_[:, 0:2**(3+i)].shape}\")\n",
    "            x__ = layer(x_[:, 0:2**(3+i)])\n",
    "            # print(f\"Subset output: {x__.shape}\")\n",
    "            output.append(x__)\n",
    "\n",
    "        output = torch.stack(output, dim=1)\n",
    "        # print(f\"Final output: {output.shape}\")\n",
    "        return output, x_\n",
    "\n",
    "def create_model(in_dimensions: int, dims: int, num_labels: int):\n",
    "    \"\"\"\n",
    "    Create model\n",
    "    \"\"\"\n",
    "\n",
    "    model = AnimalClassifierMatryoshka(in_dimensions, dims, num_labels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "\n",
    "DEVICE = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() \\\n",
    "        else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "# DEVICE = torch.device('cpu')\n",
    "\n",
    "CONFIG = Namespace(\n",
    "    run_name='animal-classifier',\n",
    "    image_size=256,\n",
    "    hidden_dims=256,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=1,\n",
    "    seed=1\n",
    "    )\n",
    "CONFIG.device = DEVICE\n",
    "\n",
    "MODEL_ARTIFACT = './artifacts/animal-classifier-model-v1:v2'\n",
    "if not os.path.exists(MODEL_ARTIFACT):\n",
    "    run = wandb.init(project='Animal-Classifier', entity=None,\n",
    "                     job_type='visualize',\n",
    "                     name=CONFIG.run_name,\n",
    "                     config=CONFIG)\n",
    "    artifact = run.use_artifact('pkthunder/Animal-Classifier/animal-classifier-model-v1:v2', type='model')\n",
    "    artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(config: Namespace):\n",
    "    \"\"\"\n",
    "    Prepare dataloader\n",
    "    \"\"\"\n",
    "\n",
    "    preprocess = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((config.image_size, config.image_size)),  # Resize\n",
    "            # transforms.RandomHorizontalFlip(p=config.horizontal_flip_prob),\n",
    "            # transforms.GaussianBlur(kernel_size=config.gaussian_blur_kernel_size),\n",
    "            transforms.ToTensor(),  # Convert to tensor (0, 1)\n",
    "            transforms.Normalize([0.5], [0.5]),  # Map to (-1, 1)\n",
    "        ])\n",
    "    \n",
    "    # For pre-processing original image for visualization in W&Bs\n",
    "    preprocess_original = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((512, 512)),  # Resize\n",
    "            transforms.ToTensor(),  # Convert to tensor (0, 1)\n",
    "        ])\n",
    "\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = load_dataset('cats_vs_dogs')\n",
    "    # Remove images that are 100x100 or below.\n",
    "    dataset = \\\n",
    "        dataset.filter(\n",
    "            lambda example: example['image'].size[0] > 100 and example['image'].size[1] > 100)\n",
    "\n",
    "    def transform(examples):\n",
    "        images = [preprocess(image.convert('RGB')) for image in examples['image']]\n",
    "        original_images = [\n",
    "            preprocess_original(image.convert('RGB')) \\\n",
    "                for image in examples['image']]\n",
    "\n",
    "        return {'image': images,\n",
    "                'label': examples['labels'],\n",
    "                'original-image': original_images\n",
    "                }\n",
    "\n",
    "    # Split dataset into train + val. Balance train + val\n",
    "    num_points = len(dataset['train'])\n",
    "    labels = dataset['train']['labels']\n",
    "\n",
    "    split_df = pd.DataFrame()\n",
    "    split_df['labels'] = labels\n",
    "    split_df['id'] = list(range(num_points))\n",
    "    split_df['fold'] = -1\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=config.seed)\n",
    "    for i, (_, test_ids) in enumerate(cv.split(np.zeros(num_points), labels)):\n",
    "        split_df.loc[test_ids, ['fold']] = i\n",
    "\n",
    "    split_df['split'] = 'train'\n",
    "    split_df.loc[split_df.fold == 0, ['split']] = 'val'\n",
    "\n",
    "    # print(split_df[split_df['split'].str.fullmatch('train')].labels.value_counts())\n",
    "    # print(split_df[split_df['split'].str.fullmatch('val')].labels.value_counts())\n",
    "\n",
    "    train_indices = split_df[split_df['split'].str.fullmatch('train')]['id']\n",
    "    val_indices = split_df[split_df['split'].str.fullmatch('val')]['id']\n",
    "\n",
    "    def train_generator():\n",
    "        for idx in train_indices:\n",
    "            yield dataset['train'][idx]\n",
    "\n",
    "    def val_generator():\n",
    "        for idx in val_indices:\n",
    "            yield dataset['train'][idx]\n",
    "\n",
    "    train_dataset = Dataset.from_generator(train_generator)\n",
    "    val_dataset = Dataset.from_generator(val_generator)\n",
    "\n",
    "    train_dataset.set_transform(transform)\n",
    "    val_dataset.set_transform(transform)\n",
    "\n",
    "    train_gen = torch.Generator().manual_seed(config.seed)\n",
    "    val_gen = torch.Generator().manual_seed(config.seed)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=config.per_device_train_batch_size,\n",
    "        shuffle=True, generator=train_gen)\n",
    "    \n",
    "    val_dataloader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=config.per_device_eval_batch_size,\n",
    "        shuffle=True, generator=val_gen)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = create_model(3, CONFIG.hidden_dims, 2)\n",
    "MODEL.load_state_dict(torch.load(f\"{MODEL_ARTIFACT}/model.pt\", map_location=torch.device('cpu')))\n",
    "MODEL.to(CONFIG.device)\n",
    "MODEL.eval()\n",
    "\n",
    "# We are going to visualize the validation data\n",
    "_, val_dataloader = prepare_dataloader(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_embeddings(model: AnimalClassifierMatryoshka, dataloader):\n",
    "    \"\"\"\n",
    "    Get embeddings from feature encoder backbone\n",
    "    \"\"\"\n",
    "\n",
    "    features_by_subset = {}\n",
    "    inst_labels = []\n",
    "\n",
    "    # Initialize subset buckets\n",
    "    for i in range(len(model.linear_layers)):\n",
    "        features_by_subset[i] = []\n",
    "\n",
    "    for _, batch in enumerate(dataloader):\n",
    "        _, features = model(batch['image'].to(CONFIG.device))\n",
    "        label = batch['label']\n",
    "\n",
    "        for i in range(len(model.linear_layers)):\n",
    "            features_by_subset[i].append(features[:, 0:2**(3+i)].cpu())\n",
    "        animal_label = 'cat' if label[0].item() == 0 else 'dog'\n",
    "        inst_labels.append(animal_label)\n",
    "\n",
    "    for i in range(len(model.linear_layers)):\n",
    "        features_by_subset[i] = torch.concat(features_by_subset[i], axis=0)\n",
    "        print(f\"Shape of features for subset {i}: {features_by_subset[i].shape}\")\n",
    "\n",
    "    return features_by_subset, inst_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "features_by_subset, inst_labels = get_embeddings(MODEL, val_dataloader)\n",
    "for subset_id, features in features_by_subset.items():\n",
    "    features_by_subset[subset_id] = normalize(features)\n",
    "\n",
    "# # L2 Norm the embeddings\n",
    "# pretrained_embeddings = normalize(pretrained_embeddings)\n",
    "# finetuned_embeddings = normalize(finetuned_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(font_scale=2.5)\n",
    "plt.set_cmap('tab20')\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = plt.get_cmap('tab20')\n",
    "\n",
    "unique_labels = []\n",
    "for label in inst_labels:\n",
    "    if label not in unique_labels:\n",
    "        unique_labels.append(label)\n",
    "\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "for subset_id, features in features_by_subset.items():\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_embedding = pca.fit_transform(features)\n",
    "    df = pd.DataFrame(pca_embedding, columns=['pca1', 'pca2'])\n",
    "    df['label'] = inst_labels\n",
    "    df['subset_id'] = subset_id\n",
    "\n",
    "    fig = plt.figure(figsize=(13, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    num_labels = len(unique_labels)\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        label_df = df[df.label == label]\n",
    "        ax.scatter(label_df.pca1, label_df.pca2, label=str(label), c=color_map(i))\n",
    "\n",
    "    ax.set_xlabel(\"PCA Dimension 1\")\n",
    "    ax.set_ylabel(\"PCA Dimension 2\")\n",
    "    # ax.set_zlabel(\"PCA Dimension 3\")\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.7, box.height])\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1.00, 0.5))\n",
    "    fig.savefig(f\"subset-{subset_id+1}-features.png\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "animal-representation-learning-yALp4Exd-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
